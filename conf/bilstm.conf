source $DEEP_META_ROOT/conf/global.conf

export network="bilstm"
export model_dir="$models_dir/$network"

source $DEEP_META_ROOT/conf/pmc-embeddings.conf

# model hyperparameters
num_filters=150
filter_width=3
nonlinearity="relu"
initialization="orthogonal"
model="bilstm"
start_end="false"
predict_pad="false"

# use pruned PMC train and dev sets -- load this AFTER filter_width is set
export train_dir="$HOME/data/pruned_pmc/train-30-lex/"
export dev_dir="$HOME/data/pruned_pmc/dev-30-lex"
export data_dir="$processed_data_dir/$data_name-w$filter_width-$embeddings_name"

# train-0.001-0.9-1e-6-0.85-0.65-1.0-0.5-64-150-0.0-tanh-5-10-1e-5.log	93.21
# train-0.001-0.99-1e-4-0.85-0.85-1.0-0.5-32-150-0.0-tanh-5-10-1e-5.log	93.29

# training hyperparameters
lr=0.001
hidden_dropout=0.85
input_dropout=0.65
word_dropout=0.5
batch_size=64
l2=0.0
clip_grad=10
drop_penalty=1e-5
beta2=0.9
epsilon=1e-6
