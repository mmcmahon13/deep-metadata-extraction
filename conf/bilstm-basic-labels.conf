source $DEEP_META_ROOT/conf/global.conf

export network="bilstm-geo-lex"
export model_dir="$models_dir/$network"

source $DEEP_META_ROOT/conf/pmc-embeddings.conf

# model hyperparameters
num_filters=150
filter_width=3
nonlinearity="relu"
initialization="orthogonal"
model="bilstm"
start_end="false"
predict_pad="false"

# use pruned PMC train and dev sets -- load this AFTER filter_width is set
export train_dir="$HOME/data/pruned_pmc/train-30-lex-scaled/"
export dev_dir="$HOME/data/pruned_pmc/dev-30-lex-scaled/"
export test_dir="$HOME/data/pruned_pmc/test-30-lex-scaled/"
export data_dir="$processed_data_dir/$data_name-w$filter_width-$embeddings_name"

# training hyperparameters
lr=0.001
hidden_dropout=0.75
input_dropout=0.75
word_dropout=0.5
batch_size=64
l2=1e-6
clip_grad=10
drop_penalty=1e-5
beta2=0.9
epsilon=1e-4

#prev l2: 0.0

# "train-$lr-$beta2-$epsilon-$h_dropout-$i_dropout-$m_dropout-$w_dropout-$batch_size-$num_filter-$l2-$nonlinearity-$shape_dim-$clip_grad-$drop_penalty"

# train-0.001(lr)-0.9(beta2)-1e-4(epsilon)-0.75(hdrop)-0.75(idrop)-1.0(mdrop)-0.5(wdrop)-64(batch)-150(filter)-1e-6(l2)-tanh-5-1-1e-5(drop-pen).log:Weighted       0.890649
